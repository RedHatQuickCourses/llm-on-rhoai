<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Jupyter Notebooks :: Serving an LLM using OpenShift AI</title>
    <link rel="prev" href="index.html">
    <link rel="next" href="section2.html">
    <meta name="generator" content="Antora 3.1.3">
    <link rel="stylesheet" href="../../../_/css/site.css">
    <script>var uiRootPath = '../../../_'</script>
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar">
    <div class="navbar-brand">
      <a class="navbar-item" href="https://www.redhat.com" target="_blank"><img src="../../../_/img/redhat-logo.png" height="40px" alt="Red Hat"></a>
      <a class="navbar-item" style="font-size: 24px; color: white" href="../../..">Serving an LLM using OpenShift AI</a>
      <button class="navbar-burger" data-target="topbar-nav">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
        <a class="navbar-item" href="https://github.com/RedHatQuickCourses/changeme/issues" target="_blank">Report Issues</a>
      </div>
    </div>
  </nav>
</header><div class="body">
<div class="nav-container" data-component="model-serving" data-version="1.1">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="../index.html">Serving an LLM using OpenShift AI</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../index.html">Home</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../chapter1/index.html">Technical Component Intoduction</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter1/section1.html">Red Hat OpenShift AI</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter1/section2.html">Large Language Models</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../chapter2/index.html">OpenShift AI Initialization</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter2/section1.html">Installing Red&#160;Hat OpenShift AI Using the Web Console</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter2/section2.html">Modifying the OpenShift AI TLS Certificate</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter2/section3.html">Configure the OpenShift AI Data Science Cluster</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../chapter3/index.html">OpenShift AI Configuration</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter3/section1.html">Creating OpenShift AI Resources - 1</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter3/section2.html">MinIO S3 Compatible Storage Setup</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter3/section3.html">OpenShift AI Resources - 2</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="index.html">Jupyter Notebooks &amp; LLMs</a>
<ul class="nav-list">
  <li class="nav-item is-current-page" data-depth="2">
    <a class="nav-link" href="section1.html">Jupyter Notebooks</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="section2.html">Mistral LLM Model Inference</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="section3.html">Llama3 LLM Model Inference</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">Serving an LLM using OpenShift AI</span>
    <span class="version">1.1</span>
  </div>
  <ul class="components">
    <li class="component is-current">
      <a class="title" href="../index.html">Serving an LLM using OpenShift AI</a>
      <ul class="versions">
        <li class="version is-current is-latest">
          <a href="../index.html">1.1</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
  <a href="../index.html" class="home-link"></a>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="../index.html">Serving an LLM using OpenShift AI</a></li>
    <li><a href="index.html">Jupyter Notebooks &amp; LLMs</a></li>
    <li><a href="section1.html">Jupyter Notebooks</a></li>
  </ul>
</nav>
</div>
  <div class="content">
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
<article class="doc">
<h1 class="page">Jupyter Notebooks</h1>
<div class="sect1">
<h2 id="_open_jupyterlab"><a class="anchor" href="#_open_jupyterlab"></a>Open JupyterLab</h2>
<div class="sectionbody">
<div class="paragraph">
<p>JupyterLab enables you to work with documents and activities such as Jupyter notebooks, text editors, terminals, and custom components in a flexible, integrated, and extensible manner. For a demonstration of JupyterLab and its features, <a href="https://jupyterlab.readthedocs.io/en/stable/getting_started/overview.html#what-will-happen-to-the-classic-notebook">you can view this video.</a></p>
</div>
<div class="paragraph">
<p>Return to the ollama-model workbench dashboard in the OpenShift AI console.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Select the <strong>Open</strong> link to the right of the status section.</p>
<div class="imageblock">
<div class="content">
<img src="_images/oai_open_jupyter.png" alt="oai open jupyter" width="640">
</div>
</div>
</li>
<li>
<p>When the new window opens, use the OpenShift admin user &amp; password to login to JupyterLab.</p>
</li>
<li>
<p>Click <strong>Allow selected permissions</strong> button to complete login to the notebook.</p>
</li>
</ol>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
If the <strong>OPEN</strong> link for the notebook is grayed out, the notebook container is still starting. This process can take a few minutes &amp; up to 20+ minutes depending on the notebook image we opted to choose.
</td>
</tr>
</table>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_inside_jupyterlab"><a class="anchor" href="#_inside_jupyterlab"></a>Inside JupyterLab</h2>
<div class="sectionbody">
<div class="paragraph">
<p>This takes us to the JupyterLab screen where we can select multiple options / tools / to work to begin our data science experimentation.</p>
</div>
<div class="paragraph">
<p>Our first action is to clone a git repository that contains a collection of LLM projects including  the notebook we are going to use to interact with the LLM.</p>
</div>
<div class="paragraph">
<p>Clone the github repository to interact with the Ollama Framework from this location:
<a href="https://github.com/rh-aiservices-bu/llm-on-openshift.git" class="bare">https://github.com/rh-aiservices-bu/llm-on-openshift.git</a></p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Copy the URL link above</p>
</li>
<li>
<p>Click on the Clone a Repo Icon above explorer section window.</p>
<div class="imageblock">
<div class="content">
<img src="_images/clone_a_repo.png" alt="clone a repo" width="640">
</div>
</div>
</li>
<li>
<p>Paste the link into the <strong>clone a repo</strong> pop up,   make sure the <strong>included submodules are checked</strong>, then click the clone.</p>
</li>
<li>
<p>Navigate to the llm-on-openshift/examples/notebooks/langchain folder:</p>
</li>
<li>
<p>Then open the file: <em>Langchain-Ollama-Prompt-memory.ipynb</em></p>
<div class="imageblock">
<div class="content">
<img src="_images/navigate_ollama_notebook.png" alt="navigate ollama notebook" width="640">
</div>
</div>
</li>
<li>
<p>Explore the notebook, and then continue.</p>
</li>
</ol>
</div>
<div class="sect2">
<h3 id="_configure_the_ollama_framework_with_a_large_language_model"><a class="anchor" href="#_configure_the_ollama_framework_with_a_large_language_model"></a>Configure the Ollama Framework with a Large Language Model</h3>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>From the Notebook page, add a new cell above the inference url</p>
<div class="imageblock">
<div class="content">
<img src="_images/add_a_cell.png" alt="add a cell" width="640">
</div>
</div>
</li>
</ol>
</div>
<div class="paragraph">
<p>The Ollama Model Runtime we deployed using the Single Model Serving Platform in OpenShift AI is a Framework that can host various large language models. It is currently running, but is waiting for the command to instruct the framework on which model to download and serve.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>To load the mistral model, we are going use the following python code to instruct the runtime to download and serve a quantized 4 bit version of the mistral large language model.</p>
</li>
<li>
<p>Copy the code below and paste this code in the new cell added to the notebook in the previous step.</p>
</li>
</ol>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-yaml hljs" data-lang="yaml">import requests

headers = {
    # Already added when you pass json=
    # 'Content-Type': 'application/json',
}

json_data = {
    'name': 'mistral',
}

response = requests.post('https://your-endpoint/api/pull', headers=headers, json=json_data, verify=False)</code></pre>
</div>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/inference_server_url.png" alt="inference server url" width="640">
</div>
</div>
<div class="paragraph">
<p>We&#8217;ll need to modify the url in the bottom line beginning with <strong>response =</strong> in the next step.</p>
</div>
</div>
<div class="sect2">
<h3 id="_update_the_inference_endpoints"><a class="anchor" href="#_update_the_inference_endpoints"></a>Update the Inference Endpoints</h3>
<div class="paragraph">
<p>Head back to the RHOAI ollama-model workbench dashboard, from the models tab, copy the inference endpoint for the ollama-mistral model.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/inference_endpoint.png" alt="inference endpoint" width="640">
</div>
</div>
<div class="paragraph">
<p>Return the Jupyter notebook</p>
</div>
<div class="paragraph">
<p>We will be updating two cells with the inference endpoint.</p>
</div>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>Replace the <a href="https://your-endopint" class="bare">https://your-endopint</a> section of the python code we copied into the new cell. Ensure you leave the <strong>/api/pull</strong> portion appended to the url.</p>
</li>
<li>
<p>Replace the red text inside the quotation marks for the inference_server_url with the same inference endpoint url.</p>
</li>
</ol>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/replaced_endpoints2.png" alt="replaced endpoints2" width="640">
</div>
</div>
</div>
<div class="sect2">
<h3 id="_execute_cell_code_to_assemble_the_langchain_components"><a class="anchor" href="#_execute_cell_code_to_assemble_the_langchain_components"></a>Execute cell code to assemble the langchain components</h3>
<div class="olist arabic">
<ol class="arabic">
<li>
<p>We can now start executing the code in the cells, begin with the new cell added to the top.  Click on the cell to activate blue indicator to the left of the cell. Next click on the play icon to run the selected cells and advanced to the next. While the cell is executing, an <strong>*</strong> (asterisk icon) will appear in the brackets, when complete this will change to a number.</p>
<div class="imageblock">
<div class="content">
<img src="_images/execute_cell2.png" alt="execute cell2" width="640">
</div>
</div>
<div class="olist loweralpha">
<ol class="loweralpha" type="a">
<li>
<p>You will receive a message about an Unverified HTTPs request. This is because we didn’t use authentication for this application.  You can ignore this for this lab experience, but in production we would enable authentication using Authorino secured connections.</p>
</li>
<li>
<p>The mistral model files are now being downloaded to the Ollama Framework. This may take a few minutes, the <strong>*</strong> will change to a number when complete.</p>
</li>
</ol>
</div>
</li>
<li>
<p>Continue executing through the cells.</p>
</li>
<li>
<p>Next we run the cell: <strong>!pip install -q langchain==0.1.14</strong> ; there is a notice to update pip; ignore and continue.</p>
</li>
<li>
<p>The next cell imports the <strong>langchain components</strong> that provide the libraries and programming files to interact with our LLM.</p>
</li>
<li>
<p>This <strong>"Create the LLM instance"</strong> cell sets the variables that determine how we are going to interact with our model  and how it should respond - sets that into an array using <strong>llm</strong> variable.</p>
</li>
<li>
<p>Next run the <strong>"Create the prompt"</strong> cell.  Here we are setting the <strong>template</strong> variable with the details of how the model operate, including constraints and boundries when generating the response. We often to not experience the system message when interacting with an LLM, but this is a standard field that is included along with the user prompt.</p>
</li>
<li>
<p>Continue executing the cells, <strong>"memory for the conversation"</strong> keeps the previous context / conversation history so full history of the chat conversation is sent as part of the prompt.</p>
</li>
<li>
<p>The <strong>create the chain</strong> cell, combines each of previous variables: llm, prompt, memory, and adds a verbose boolean to create the conversation variable, which will be sent to Models inference endpoint running in OpenShift AI.  The verbose option set to true displays the entire conversation sent to the Model in the notebook before the Models (AI&#8217;s) response.</p>
</li>
</ol>
</div>
<div class="paragraph">
<p>In the next, section, we&#8217;ll send our first input to the running Mistral Large Language Model.</p>
</div>
</div>
</div>
</div>
<nav class="pagination">
  <span class="prev"><a href="index.html">Jupyter Notebooks &amp; LLMs</a></span>
  <span class="next"><a href="section2.html">Mistral LLM Model Inference</a></span>
</nav>
</article>
  </div>
</main>
</div>
<footer class="footer">
  <img src="../../../_/img/rhl-logo-red.png" height="40px" alt="Red Hat"  href="https://redhat.com" >
</footer><script id="site-script" src="../../../_/js/site.js" data-ui-root-path="../../../_"></script>
<script async src="../../../_/js/vendor/highlight.js"></script>
  </body>
</html>
