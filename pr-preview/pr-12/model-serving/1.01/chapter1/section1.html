<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Technology Components :: Serving LLM Models on OpenShift AI</title>
    <link rel="prev" href="index.html">
    <link rel="next" href="../chapter2/index.html">
    <meta name="generator" content="Antora 3.1.3">
    <link rel="stylesheet" href="../../../_/css/site.css">
    <script>var uiRootPath = '../../../_'</script>
  </head>
  <body class="article">
<header class="header">
  <nav class="navbar">
    <div class="navbar-brand">
      <a class="navbar-item" href="https://www.redhat.com" target="_blank"><img src="../../../_/img/redhat-logo.png" height="40px" alt="Red Hat"></a>
      <a class="navbar-item" style="font-size: 24px; color: white" href="../../..">Serving LLM Models on OpenShift AI</a>
      <button class="navbar-burger" data-target="topbar-nav">
        <span></span>
        <span></span>
        <span></span>
      </button>
    </div>
    <div id="topbar-nav" class="navbar-menu">
      <div class="navbar-end">
        <a class="navbar-item" href="https://github.com/RedHatQuickCourses/changeme/issues" target="_blank">Report Issues</a>
      </div>
    </div>
  </nav>
</header><div class="body">
<div class="nav-container" data-component="model-serving" data-version="1.01">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="../index.html">Serving LLM Models on OpenShift AI</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="../index.html">Home</a>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="index.html">Technical side of LLMs</a>
<ul class="nav-list">
  <li class="nav-item is-current-page" data-depth="2">
    <a class="nav-link" href="section1.html">Technology Components</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../chapter2/index.html">OpenShift AI Initilization</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter2/section1.html">Installing Red&#160;Hat OpenShift AI Using the Web Console</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter2/section2.html">Modifying the OpenShift AI TLS Certificate</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../chapter3/index.html">OpenShift AI Configuration</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter3/section1.html">OpenShift AI Customization</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../chapter3/section2.html">Jupyter Notebooks &amp; Mistral LLM Model Setup</a>
  </li>
</ul>
  </li>
</ul>
  </li>
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="../appendix/appendix.html">Knowledge Check</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../appendix/section1.html">Quiz: Components of Red Hat OpenShift AI</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="../appendix/section2.html">Answers to the Quiz</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">Serving LLM Models on OpenShift AI</span>
    <span class="version">1.01</span>
  </div>
  <ul class="components">
    <li class="component is-current">
      <a class="title" href="../index.html">Serving LLM Models on OpenShift AI</a>
      <ul class="versions">
        <li class="version is-current is-latest">
          <a href="../index.html">1.01</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
<button class="nav-toggle"></button>
  <a href="../index.html" class="home-link"></a>
<nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="../index.html">Serving LLM Models on OpenShift AI</a></li>
    <li><a href="index.html">Technical side of LLMs</a></li>
    <li><a href="section1.html">Technology Components</a></li>
  </ul>
</nav>
</div>
  <div class="content">
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>
<article class="doc">
<h1 class="page">Technology Components</h1>
<div class="sect1">
<h2 id="_kubernetes_openshift"><a class="anchor" href="#_kubernetes_openshift"></a>Kubernetes &amp; OpenShift</h2>
<div class="sectionbody">
<div class="paragraph">
<p>OpenShift builds upon Kubernetes by providing an enhanced platform with additional capabilities. It simplifies the deployment and management of Kubernetes clusters while adding enterprise features, developer tools, and security enhancements.</p>
</div>
<div class="paragraph">
<p>In addition, Openshift provides a Graphic User Interface for Kubernetes. Openshift AI runs on Openshift; therefore, the engine under the hood of both products is Kubernetes.</p>
</div>
<div class="paragraph">
<p>Most workloads are deployed in kubernetes via YAML files. A Kubernetes Deployment YAML file is a configuration file written in YAML (YAML Ain&#8217;t Markup Language) that defines the desired state of a Kubernetes Deployment. These YAML file are used to create, update, or delete Deployments in Kubernetes / OpenShift clusters.</p>
</div>
<div class="paragraph">
<p>Donâ€™t worry about needing to know how to write these files. That&#8217;s what OpenShift &amp; OpenShift AI will take care of for us.  In this course,  we will just need to select the options we want in the UI. OpenShift and OpenShift AI will take care of creating the YAML deployment files.</p>
</div>
<div class="paragraph">
<p>We will have to perform a few YAML file copy-and-paste operations; instructions are provided in the course.</p>
</div>
<div class="paragraph">
<p>Just know, YAML files create resources directly in the Kubernetes platform. We primarily use the OpenShift AI UI to perform these tasks to deliver our LLM.</p>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_large_language_models"><a class="anchor" href="#_large_language_models"></a>Large Language Models</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Large Language Models (LLMs) can generate new stories, summarize texts, and even perform advanced tasks like reasoning and problem solving, which is not only impressive but also remarkable due to their accessibility and easy integration into applications.</p>
</div>
<div class="paragraph">
<p>As you probably already know,  training large language models is expensive, time consuming, and most importantly requires a vast amount of data fed into the model.</p>
</div>
<div class="paragraph">
<p>The common outcome from this training is a Foundation model: an LLM designed to generate and understand human-like text across a wide range of use cases.</p>
</div>
<div class="paragraph">
<p>The key to this powerful language processing architecture, <strong>is the Transformer!</strong> A helpful definition of a <strong>Transformer</strong> is a set of neural networks that consist of an encoder and a decoder with self-attention capabilities.  The Transformer was created by Google and started as a language translation algorithm.  It analyzes relationships between words in text, which crucial for LLMs to understand and generate language.</p>
</div>
<div class="paragraph">
<p>This is how LLMs are able to predict the next words, by using the transformer neural network &amp; attention mechanism to focus in on keywords to determine context. Then use that context and <em>knowledge</em> from all the data ingested to predict the next word after a sequence of words.</p>
</div>
<div class="sect2">
<h3 id="_modifications_to_llms"><a class="anchor" href="#_modifications_to_llms"></a>Modifications to LLMs</h3>
<div class="paragraph">
<p>As mentioned above, LLMs are normally large, require Graphics Cards, and costly compute resources to load the model into memory.</p>
</div>
<div class="paragraph">
<p>However, there are  techniques for compressing large LLM models, making them smaller and faster to run on devices with limited resources.</p>
</div>
<div class="ulist">
<ul>
<li>
<p>Quantization reduces the precision of numerical representations in large language models to make them more memory-efficient during deployment.</p>
</li>
<li>
<p>Reducing the precision of LLM parameters to save computational resources without sacrificing performance. Trimming surplus connections or parameters to make LLMs smaller and faster yet performant.</p>
</li>
</ul>
</div>
<div class="paragraph">
<p>In this course, we will be using a quantized version of the Mistral Large Language Model.  Instead of requiring 24Gb of memory and Graphics processing unit to simulate the neural network, we are going to run our model with  4 CPUs and 8GB of ram, burstable to 8 CPU with 10Gb ram max.</p>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<a href="https://www.redhat.com/en/topics/ai/what-is-instructlab"><strong>InstructLabs</strong></a>- runs locally on laptops uses this same type of quantized LLMs, Both the Granite &amp; Mixtral Large Language Models are reduced in precision to operate on a laptop.
</td>
</tr>
</table>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_the_ollama_model_framework"><a class="anchor" href="#_the_ollama_model_framework"></a>The Ollama Model Framework</h2>
<div class="sectionbody">
<div class="paragraph">
<p>There are hundreds of popular LLMs, nonetheless, their operation remains the same: users provide instructions or tasks in natural language, and the LLM generates a response based on what the model "thinks" could be the continuation of the prompt.</p>
</div>
<div class="paragraph">
<p>Ollama is not an LLM Model - Ollama is a relatively new but powerful open-source framework designed for serving machine learning models. It&#8217;s designed to be efficient, scalable, and easy to use; making it an attractive option for developers and organizations looking to deploy their AI models into production.</p>
</div>
<div class="sect2">
<h3 id="_how_does_ollama_work"><a class="anchor" href="#_how_does_ollama_work"></a>How does Ollama work?</h3>
<div class="paragraph">
<p>At its core, Ollama simplifies the process of downloading, installing, and interacting with a wide range of LLMs, empowering users to explore their capabilities without the need for extensive technical expertise or reliance on cloud-based platforms.</p>
</div>
<div class="paragraph">
<p>In this course, we will focus on single LLM, Mistral, run on the Ollama Framework. However, with the understanding of the Ollama Framework, we will be able to work with a variety of large language models utilizing the exact same configuration.</p>
</div>
<div class="paragraph">
<p>You will be able to switch models in minutes, all running on the same platform. This will enable you test, compare, and evalute multiple models with the skills gained in the course.</p>
</div>
</div>
</div>
</div>
<nav class="pagination">
  <span class="prev"><a href="index.html">Technical side of LLMs</a></span>
  <span class="next"><a href="../chapter2/index.html">OpenShift AI Initilization</a></span>
</nav>
</article>
  </div>
</main>
</div>
<footer class="footer">
  <img src="../../../_/img/rhl-logo-red.png" height="40px" alt="Red Hat"  href="https://redhat.com" >
</footer><script id="site-script" src="../../../_/js/site.js" data-ui-root-path="../../../_"></script>
<script async src="../../../_/js/vendor/highlight.js"></script>
  </body>
</html>
