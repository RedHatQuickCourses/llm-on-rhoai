= Serving an LLM using OpenShift AI
:navtitle: Home


video::intro_v5.mp4[width=640]

Welcome to this quick course on _Serving an LLM using OpenShift AI_. 

This program was designed to guide you through the process of installing an OpenShift AI Platform using the OpenShift Container Platform Web Console UI. We get hands-on experience in each component needed to enable a RHOAI Platform using an Openshift Container Platform Cluster. 

Once we have an operational OpenShift AI Platform, we will login and begin the configuration of: model runtimes, data science projects, data connections, & finally use a jupyter notebook to infer the answers to easy questions. 

There will be some challenges along the way, all designed to teach us about a component, or give us the knowledge needed to utilize OpenShift AI and host a Large Language Model. 

If you're ready, letâ€™s get started!


IMPORTANT: The hands-on labs in this course were created and tested with RHOAI v2.10 & later versions. Labs will work without any changes in minor dot release upgrades of the product. https://github.com/RedHatQuickCourses/llm-on-rhoai[Please open issues in this repository if you face any problem.]


== Authors

The PTL team acknowledges the valuable contributions of the following Red Hat associates:

 * Christopher Nuland

 * Vijay Chebolu

 * Noel O'Conner

 * Hunter Gerlach

 * Karlos Knox

== Classroom Environment

We will use the https://demo.redhat.com/catalog?item=babylon-catalog-prod%2Fopenshift-cnv.ocpmulti-wksp-cnv.prod[*Red Hat OpenShift Container Platform Cluster*] catalog item in the Red Hat Demo Platform (RHDP) to run the hands-on exercises in this course.

[TIP]
If you are planning on starting this course now, go ahead & launch the workshop. It takes ~15 minutes to provision it, which is just enough time to finish the introduction section. 

video::demohub_resources_v4.mp4[width=640]

When ordering this catalog item in RHDP:

  . Select Practice/Enablement for the Activity field

  . Select Learning about the Product for the Purpose field

  . Leave the Salesforce ID field blank

  . Scroll to the bottom, read the usage cost section, then check the box to confirm acceptance of terms and conditions

  . Click order

For Red Hat partners who do not have access to RHDP, provision an environment using the Red Hat Hybrid Cloud Console. Unfortunately, the labs will NOT work on the trial sandbox environment. You need to provision an OpenShift AI cluster on-premises, or in the supported cloud environments by following the product documentation at https://docs.redhat.com/en/documentation/red_hat_openshift_ai_self-managed/2.10/html/installing_and_uninstalling_openshift_ai_self-managed/index[Product Documentation for installing Red Hat OpenShift AI 2.10].

== Prerequisites

 * Basic experience with Red Hat OpenShift Container Platform is recommended but is not mandatory.  

* We will encounter & modify code segments, deploy resources using YAML files, & modify launch configurations; but we will not have to write code.

== Objectives

The overall objectives of this course include:

 * Utilize Red Hat OpenShift AI to serve & interact with an LLM

 * Install Red Hat OpenShift AI operators & dependencies

 * Add a custom model serving runtime

 * Create a data science project, workbench & data connections

 * Load an LLM model into the Ollama runtime framework

 * Import (from git repositories), interact with LLM model via Jupyter Notebooks

 * Experiment with the Mistral LLM and Llama3 large language models