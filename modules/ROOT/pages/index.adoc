= Serving LLM Models on OpenShift AI
:navtitle: Home

Welcome to this Quick course on _Deploying an LLM using OpenShift AI_. This is the first of a set of advanced courses about Red Hat OpenShift AI:

IMPORTANT: The hands-on labs in this course were created and tested with RHOAI v2.9.1. Labs should mostly work without any changes in minor dot release upgrades of the product. Please open issues in this repository if you face any issue.


== Authors

The PTL team acknowledges the valuable contributions of the following Red Hat associates:

*Christopher Nuland

*Vijay Chebolu & Team

*Karlos Knox

== Classroom Environment

This introductory course has a few, simple hands-on labs. You will use the Base RHOAI on AWS catalog item in the Red Hat Demo Platform (RHDP) to run the hands-on exercises in this course.

This course will utlize the *Red Hat OpenShift Container Platform Cluster*.

When ordering this catalog item in RHDP:

  * Select Practice/Enablement for the Activity field

  * Select Learning about the Product for the Purpose field

  * Enter Learning RHOAI in the Salesforce ID field

  * Scroll to the bottom, check the box to confirm acceptance of terms and conditions

  * Click order

For Red Hat partners who do not have access to RHDP, provision an environment using the Red Hat Hybrid Cloud Console. Unfortunately, the labs will NOT work on the trial sandbox environment. You need to provision an OpenShift AI cluster on-premises, or in the supported cloud environments by following the product documentation at Product Documentation for Red Hat OpenShift AI 2024.

== Prerequisites

For this course, basic experience with Red Hat OpenShift is recommended but is not mandatory.  

You will encounter & modify code segments, deploy resources using Yaml files, and have to modify launch configurations, but you will not have to write code.

== Objectives

The overall objectives of this introductory course include:

 * Familiarize utilizing Red Hat OpenShift AI to Serve & Interact with an LLM.

 * Installing Red Hat OpenShift AI Operator & Dependencies

 * Add a custom Model Serving Runtime

 * Create a data science project, workbench & data connections

 * Load an LLM model into the Ollama Runtime Framework

 * Import (from Git repositories), interact with LLM model via a Jupyter Notebook

 * Experiment with the Mistral LLM